<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Vision Studio - Fixed</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background: linear-gradient(135deg, #1e3c72 0%, #2a5298 100%);
            min-height: 100vh;
            color: white;
            overflow-x: hidden;
        }

        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
        }

        .header {
            text-align: center;
            margin-bottom: 30px;
            padding: 20px;
            background: rgba(255, 255, 255, 0.1);
            border-radius: 20px;
            backdrop-filter: blur(10px);
            box-shadow: 0 8px 32px rgba(0, 0, 0, 0.3);
        }

        .header h1 {
            font-size: 2.5rem;
            margin-bottom: 10px;
            background: linear-gradient(45deg, #ff6b6b, #4ecdc4);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
        }

        .debug-info {
            background: rgba(0, 0, 0, 0.3);
            padding: 15px;
            border-radius: 10px;
            margin-bottom: 20px;
            font-family: monospace;
            font-size: 14px;
            white-space: pre-wrap;
            max-height: 200px;
            overflow-y: auto;
            display: none;
        }

        .debug-toggle {
            background: rgba(255, 255, 255, 0.1);
            border: 1px solid rgba(255, 255, 255, 0.3);
            padding: 8px 16px;
            border-radius: 15px;
            margin-bottom: 20px;
            cursor: pointer;
            transition: all 0.3s ease;
            color: white;
            text-align: center;
        }

        .debug-toggle:hover {
            background: rgba(255, 255, 255, 0.2);
        }

        .controls {
            display: flex;
            flex-wrap: wrap;
            gap: 15px;
            justify-content: center;
            margin-bottom: 30px;
        }

        .control-group {
            display: flex;
            flex-direction: column;
            align-items: center;
            gap: 10px;
        }

        button,
        select,
        input[type="file"] {
            padding: 12px 24px;
            border: none;
            border-radius: 25px;
            background: linear-gradient(45deg, #ff6b6b, #4ecdc4);
            color: white;
            font-weight: bold;
            cursor: pointer;
            transition: all 0.3s ease;
            font-size: 14px;
        }

        button:hover,
        select:hover {
            transform: translateY(-2px);
            box-shadow: 0 8px 25px rgba(0, 0, 0, 0.3);
        }

        button:disabled {
            opacity: 0.5;
            cursor: not-allowed;
            transform: none;
        }

        .video-container {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 20px;
            margin-bottom: 30px;
        }

        .video-box {
            background: rgba(255, 255, 255, 0.1);
            border-radius: 20px;
            padding: 20px;
            backdrop-filter: blur(10px);
            box-shadow: 0 8px 32px rgba(0, 0, 0, 0.3);
            position: relative;
            overflow: hidden;
        }

        .video-box h3 {
            margin-bottom: 15px;
            text-align: center;
            font-size: 1.2rem;
        }

        video,
        canvas {
            width: 100%;
            height: 300px;
            object-fit: cover;
            border-radius: 15px;
            border: 2px solid rgba(255, 255, 255, 0.2);
        }

        .status {
            text-align: center;
            padding: 15px;
            background: rgba(255, 255, 255, 0.1);
            border-radius: 15px;
            margin-bottom: 20px;
            backdrop-filter: blur(10px);
        }

        .status.success {
            background: rgba(76, 175, 80, 0.2);
        }

        .status.error {
            background: rgba(244, 67, 54, 0.2);
        }

        .opencv-filters {
            display: flex;
            flex-wrap: wrap;
            gap: 10px;
            justify-content: center;
            margin-bottom: 20px;
        }

        .filter-btn {
            padding: 8px 16px;
            font-size: 12px;
            border-radius: 15px;
            background: rgba(255, 255, 255, 0.2);
            border: 1px solid rgba(255, 255, 255, 0.3);
        }

        .filter-btn.active {
            background: linear-gradient(45deg, #ff6b6b, #4ecdc4);
        }

        .loading {
            display: none;
            text-align: center;
            padding: 20px;
        }

        .spinner {
            border: 4px solid rgba(255, 255, 255, 0.3);
            border-top: 4px solid #4ecdc4;
            border-radius: 50%;
            width: 40px;
            height: 40px;
            animation: spin 1s linear infinite;
            margin: 0 auto 10px;
        }

        @keyframes spin {
            0% {
                transform: rotate(0deg);
            }

            100% {
                transform: rotate(360deg);
            }
        }

        .inference-results {
            background: rgba(255, 255, 255, 0.1);
            border-radius: 15px;
            padding: 20px;
            margin-top: 20px;
            backdrop-filter: blur(10px);
        }

        .inference-results h3 {
            margin-bottom: 15px;
            color: #4ecdc4;
        }

        .result-item {
            display: flex;
            justify-content: space-between;
            padding: 8px 0;
            border-bottom: 1px solid rgba(255, 255, 255, 0.1);
        }

        .result-item:last-child {
            border-bottom: none;
        }

        .confidence {
            font-weight: bold;
            color: #ff6b6b;
        }

        @media (max-width: 768px) {
            .video-container {
                grid-template-columns: 1fr;
            }

            .controls {
                flex-direction: column;
                align-items: center;
            }
        }
    </style>
</head>

<body>
    <div class="container">
        <div class="header">
            <h1>AI Vision Studio</h1>
            <p>Camera + OpenCV + ONNX Model Inference</p>
        </div>

        <div class="debug-toggle" id="debugToggle">üìã Toggle Debug Info</div>
        <div class="debug-info" id="debugInfo">Starting application...\n</div>

        <div class="controls">
            <div class="control-group">
                <button id="checkSystem">1. Check System</button>
                <button id="requestPermission" disabled>2. Request Permission</button>
                <button id="listCameras" disabled>3. List Cameras</button>
                <select id="cameraSelect" disabled>
                    <option value="">Select Camera</option>
                </select>
                <button id="startCamera" disabled>4. Start Camera</button>
            </div>

            <div class="control-group">
                <input type="file" id="modelFile" accept=".onnx" style="display: none;">
                <button onclick="document.getElementById('modelFile').click()">Load ONNX Model</button>
            </div>

            <div class="control-group">
                <button id="captureBtn" disabled>Capture & Analyze</button>
                <button id="toggleProcessing" disabled>Start Live Processing</button>
            </div>
        </div>

        <div class="status" id="status">
            Click "Check System" to start the camera setup process
        </div>

        <div class="loading" id="loading">
            <div class="spinner"></div>
            <p>Processing...</p>
        </div>

        <div class="video-container">
            <div class="video-box">
                <h3>Camera Feed</h3>
                <video id="videoElement" autoplay muted></video>
            </div>
            <div class="video-box">
                <h3>Processed Output</h3>
                <canvas id="outputCanvas"></canvas>
            </div>
        </div>

        <div class="opencv-filters">
            <button class="filter-btn active" data-filter="none">Original</button>
            <button class="filter-btn" data-filter="grayscale">Grayscale</button>
            <button class="filter-btn" data-filter="blur">Blur</button>
            <button class="filter-btn" data-filter="edge">Edge Detection</button>
            <button class="filter-btn" data-filter="sharpen">Sharpen</button>
            <button class="filter-btn" data-filter="emboss">Emboss</button>
        </div>

        <div class="inference-results" id="inferenceResults" style="display: none;">
            <h3>AI Model Results</h3>
            <div id="results"></div>
        </div>
    </div>

    <!-- ONNX Runtime Web -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/onnxruntime-web/1.14.0/ort.min.js"></script>

    <script>
        class IntegratedCameraApp {
            constructor() {
                this.videoElement = document.getElementById('videoElement');
                this.outputCanvas = document.getElementById('outputCanvas');
                this.ctx = this.outputCanvas.getContext('2d');
                this.currentStream = null;
                this.currentFilter = 'none';
                this.onnxSession = null;
                this.isProcessing = false;
                this.animationId = null;
                this.debugInfo = document.getElementById('debugInfo');
                this.isOpenCVReady = false;

                this.initializeApp();
            }

            log(message) {
                console.log(message);
                this.debugInfo.textContent += new Date().toLocaleTimeString() + ': ' + message + '\n';
                this.debugInfo.scrollTop = this.debugInfo.scrollHeight;
            }

            updateStatus(message, type = '') {
                const statusElement = document.getElementById('status');
                statusElement.textContent = message;
                statusElement.className = `status ${type}`;
                this.log('Status: ' + message);
            }

            initializeApp() {
                this.log('App initialized');
                this.setupEventListeners();
                this.checkOpenCVStatus();
                this.updateStatus('Click "Check System" to start debugging the camera setup');
            }

            checkOpenCVStatus() {
                if (this.isOpenCVReady) {
                    this.log('OpenCV is ready');
                } else {
                    this.log('Waiting for OpenCV to load...');
                    this.updateStatus('Loading OpenCV...');

                    // Check if OpenCV is already loaded but missed the event
                    if (typeof cv !== 'undefined' && cv.Mat) {
                        this.isOpenCVReady = true;
                        this.log('OpenCV detected as already loaded');
                        this.updateStatus('‚úÖ OpenCV loaded', 'success');
                    }
                }
            }

            setupEventListeners() {
                // Debug toggle
                document.getElementById('debugToggle').addEventListener('click', () => {
                    console.log('Debug toggle clicked');
                    const debugInfo = document.getElementById('debugInfo');
                    if (debugInfo.style.display === 'none' || debugInfo.style.display === '') {
                        debugInfo.style.display = 'block';
                        this.log('Debug info shown');
                    } else {
                        debugInfo.style.display = 'none';
                        console.log('Debug info hidden');
                    }
                });

                // Camera setup steps
                document.getElementById('checkSystem').addEventListener('click', () => {
                    console.log('Check system clicked');
                    this.checkSystem();
                });

                document.getElementById('requestPermission').addEventListener('click', () => this.requestPermission());
                document.getElementById('listCameras').addEventListener('click', () => this.listCameras());
                document.getElementById('startCamera').addEventListener('click', () => this.startCamera());

                // Processing controls
                document.getElementById('captureBtn').addEventListener('click', () => this.captureAndAnalyze());
                document.getElementById('toggleProcessing').addEventListener('click', () => this.toggleLiveProcessing());
                document.getElementById('modelFile').addEventListener('change', (e) => this.loadONNXModel(e));

                // Filter buttons
                document.querySelectorAll('.filter-btn').forEach(btn => {
                    btn.addEventListener('click', (e) => {
                        document.querySelectorAll('.filter-btn').forEach(b => b.classList.remove('active'));
                        e.target.classList.add('active');
                        this.currentFilter = e.target.dataset.filter;
                        this.log('Filter changed to: ' + this.currentFilter);
                    });
                });

                this.log('Event listeners set up');
            }

            checkSystem() {
                this.log('=== SYSTEM CHECK ===');

                // Check protocol
                this.log('Protocol: ' + window.location.protocol);
                this.log('Hostname: ' + window.location.hostname);

                // Check navigator
                this.log('Navigator exists: ' + !!navigator);
                this.log('MediaDevices exists: ' + !!navigator.mediaDevices);
                this.log('getUserMedia exists: ' + !!navigator.mediaDevices?.getUserMedia);

                // Check permissions API
                this.log('Permissions API exists: ' + !!navigator.permissions);

                // User agent
                this.log('User Agent: ' + navigator.userAgent);

                // Check for HTTPS or localhost
                const isSecureContext = window.isSecureContext;
                this.log('Secure context: ' + isSecureContext);

                if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
                    this.updateStatus('‚ùå MediaDevices API not available', 'error');
                    this.log('MediaDevices API check failed');
                    return;
                }

                if (!isSecureContext) {
                    this.updateStatus('‚ö†Ô∏è Insecure context - camera may not work properly', 'error');
                    this.log('Insecure context detected');
                } else {
                    this.updateStatus('‚úÖ System check passed', 'success');
                    this.log('System check passed - enabling request permission button');
                    document.getElementById('requestPermission').disabled = false;
                }
            }

            async requestPermission() {
                this.log('=== PERMISSION REQUEST ===');

                try {
                    this.updateStatus('Requesting camera permission...');

                    // Try the most basic camera request
                    const stream = await navigator.mediaDevices.getUserMedia({
                        video: true
                    });

                    this.log('Permission granted successfully');
                    this.log('Stream tracks: ' + stream.getTracks().length);

                    // Stop the stream
                    stream.getTracks().forEach(track => {
                        this.log('Stopping track: ' + track.kind);
                        track.stop();
                    });

                    this.updateStatus('‚úÖ Permission granted', 'success');
                    document.getElementById('listCameras').disabled = false;

                } catch (error) {
                    this.log('Permission error: ' + error.name);
                    this.log('Error message: ' + error.message);
                    this.updateStatus('‚ùå Permission denied: ' + error.name, 'error');
                }
            }

            async listCameras() {
                this.log('=== CAMERA ENUMERATION ===');

                try {
                    const devices = await navigator.mediaDevices.enumerateDevices();
                    this.log('Total devices found: ' + devices.length);

                    const cameras = devices.filter(device => device.kind === 'videoinput');
                    this.log('Video input devices: ' + cameras.length);

                    const cameraSelect = document.getElementById('cameraSelect');
                    cameraSelect.innerHTML = '<option value="">Select Camera</option>';

                    cameras.forEach((camera, index) => {
                        this.log(`Camera ${index}: ${camera.label || 'Unnamed'} (${camera.deviceId})`);

                        const option = document.createElement('option');
                        option.value = camera.deviceId;
                        option.textContent = camera.label || `Camera ${index + 1}`;
                        cameraSelect.appendChild(option);
                    });

                    if (cameras.length > 0) {
                        this.updateStatus(`‚úÖ Found ${cameras.length} camera(s)`, 'success');
                        document.getElementById('cameraSelect').disabled = false;
                        document.getElementById('startCamera').disabled = false;
                    } else {
                        this.updateStatus('‚ùå No cameras found', 'error');
                    }

                } catch (error) {
                    this.log('Enumeration error: ' + error.message);
                    this.updateStatus('‚ùå Error listing cameras: ' + error.message, 'error');
                }
            }

            async startCamera() {
                this.log('=== CAMERA START ===');

                const cameraSelect = document.getElementById('cameraSelect');
                const selectedCamera = cameraSelect.value;

                if (!selectedCamera) {
                    this.updateStatus('‚ùå Please select a camera', 'error');
                    return;
                }

                try {
                    if (this.currentStream) {
                        this.currentStream.getTracks().forEach(track => track.stop());
                    }

                    const constraints = {
                        video: {
                            deviceId: { exact: selectedCamera },
                            width: { ideal: 640 },
                            height: { ideal: 480 }
                        }
                    };

                    this.log('Using constraints: ' + JSON.stringify(constraints));

                    this.currentStream = await navigator.mediaDevices.getUserMedia(constraints);
                    this.videoElement.srcObject = this.currentStream;

                    this.videoElement.onloadedmetadata = () => {
                        this.log('Video metadata loaded');
                        this.log('Video dimensions: ' + this.videoElement.videoWidth + 'x' + this.videoElement.videoHeight);
                        this.outputCanvas.width = this.videoElement.videoWidth;
                        this.outputCanvas.height = this.videoElement.videoHeight;

                        // Enable processing buttons
                        document.getElementById('captureBtn').disabled = false;
                        document.getElementById('toggleProcessing').disabled = false;

                        this.updateStatus('‚úÖ Camera started successfully', 'success');
                    };

                } catch (error) {
                    this.log('Camera start error: ' + error.name);
                    this.log('Error message: ' + error.message);
                    this.updateStatus('‚ùå Error starting camera: ' + error.message, 'error');
                }
            }

            async loadONNXModel(event) {
                const file = event.target.files[0];
                if (!file) return;

                try {
                    this.showLoading(true);
                    this.log('Loading ONNX model: ' + file.name);
                    const arrayBuffer = await file.arrayBuffer();
                    this.onnxSession = await ort.InferenceSession.create(arrayBuffer);
                    this.updateStatus(`‚úÖ ONNX model loaded: ${file.name}`, 'success');
                    this.log('ONNX model loaded successfully');
                } catch (error) {
                    this.log('ONNX model loading error: ' + error.message);
                    this.updateStatus('‚ùå Error loading ONNX model: ' + error.message, 'error');
                } finally {
                    this.showLoading(false);
                }
            }

            applyOpenCVFilter(src) {
                let dst = new cv.Mat();

                try {
                    switch (this.currentFilter) {
                        case 'grayscale':
                            cv.cvtColor(src, dst, cv.COLOR_RGBA2GRAY);
                            cv.cvtColor(dst, dst, cv.COLOR_GRAY2RGBA);
                            break;
                        case 'blur':
                            cv.GaussianBlur(src, dst, new cv.Size(15, 15), 0, 0, cv.BORDER_DEFAULT);
                            break;
                        case 'edge':
                            cv.cvtColor(src, dst, cv.COLOR_RGBA2GRAY);
                            cv.Canny(dst, dst, 50, 150);
                            cv.cvtColor(dst, dst, cv.COLOR_GRAY2RGBA);
                            break;
                        case 'sharpen':
                            const kernel = cv.matFromArray(3, 3, cv.CV_32FC1, [0, -1, 0, -1, 5, -1, 0, -1, 0]);
                            cv.filter2D(src, dst, cv.CV_8U, kernel);
                            kernel.delete();
                            break;
                        case 'emboss':
                            const embossKernel = cv.matFromArray(3, 3, cv.CV_32FC1, [-2, -1, 0, -1, 1, 1, 0, 1, 2]);
                            cv.filter2D(src, dst, cv.CV_8U, embossKernel);
                            embossKernel.delete();
                            break;
                        default:
                            src.copyTo(dst);
                    }
                } catch (error) {
                    this.log('OpenCV filter error: ' + error.message);
                    src.copyTo(dst);
                }

                return dst;
            }

            async processFrame() {
                if (!this.videoElement.videoWidth || !this.videoElement.videoHeight) {
                    this.log('Video not ready for processing');
                    return;
                }

                try {
                    // Draw video frame to canvas
                    this.ctx.drawImage(this.videoElement, 0, 0, this.outputCanvas.width, this.outputCanvas.height);

                    // Apply OpenCV processing if available and ready
                    if (typeof cv !== 'undefined' && cv.Mat && this.isOpenCVReady) {
                        try {
                            const src = cv.imread(this.outputCanvas);
                            const processed = this.applyOpenCVFilter(src);
                            cv.imshow(this.outputCanvas, processed);

                            // Clean up
                            src.delete();
                            processed.delete();
                        } catch (cvError) {
                            this.log('OpenCV processing error: ' + cvError.message);
                            // If OpenCV fails, we still have the original image on canvas
                        }
                    } else {
                        // Show status when OpenCV is not ready
                        if (!this.isOpenCVReady) {
                            this.ctx.fillStyle = 'rgba(0, 0, 0, 0.7)';
                            this.ctx.fillRect(0, 0, this.outputCanvas.width, 30);
                            this.ctx.fillStyle = 'white';
                            this.ctx.font = '16px Arial';
                            this.ctx.fillText('OpenCV Loading...', 10, 20);
                        }
                    }
                } catch (error) {
                    this.log('Frame processing error: ' + error.message);
                }
            }

            async captureAndAnalyze() {
                if (!this.videoElement.videoWidth) {
                    this.updateStatus('‚ùå Camera not ready', 'error');
                    return;
                }

                this.showLoading(true);
                this.log('Capturing and analyzing frame');

                try {
                    await this.processFrame();

                    if (this.onnxSession) {
                        await this.runInference();
                    }
                } catch (error) {
                    this.log('Capture and analyze error: ' + error.message);
                    this.updateStatus('‚ùå Error during processing: ' + error.message, 'error');
                } finally {
                    this.showLoading(false);
                }
            }

            async runInference() {
                if (!this.onnxSession) return;

                try {
                    this.log('Running ONNX inference');

                    // Get image data from canvas
                    const imageData = this.ctx.getImageData(0, 0, this.outputCanvas.width, this.outputCanvas.height);

                    // Convert to tensor (this is a simplified example - you'll need to adjust based on your model)
                    const tensor = this.preprocessImageForModel(imageData);

                    // Run inference
                    const results = await this.onnxSession.run({ input: tensor });

                    // Process results (this is model-specific)
                    this.displayInferenceResults(results);

                } catch (error) {
                    this.log('Inference error: ' + error.message);
                    this.updateStatus('‚ùå Error during inference: ' + error.message, 'error');
                }
            }

            preprocessImageForModel(imageData) {
                // This is a simplified preprocessing - adjust based on your model requirements
                const { width, height } = imageData;
                const channels = 3;

                // Resize to model input size (example: 224x224)
                const modelWidth = 224;
                const modelHeight = 224;

                const input = new Float32Array(1 * channels * modelHeight * modelWidth);

                // Simple resize and normalization (you may need more sophisticated preprocessing)
                for (let y = 0; y < modelHeight; y++) {
                    for (let x = 0; x < modelWidth; x++) {
                        const srcX = Math.floor(x * width / modelWidth);
                        const srcY = Math.floor(y * height / modelHeight);
                        const srcIdx = (srcY * width + srcX) * 4;

                        // Normalize to [0, 1] and arrange in CHW format
                        input[y * modelWidth + x] = imageData.data[srcIdx] / 255.0; // R
                        input[modelHeight * modelWidth + y * modelWidth + x] = imageData.data[srcIdx + 1] / 255.0; // G
                        input[2 * modelHeight * modelWidth + y * modelWidth + x] = imageData.data[srcIdx + 2] / 255.0; // B
                    }
                }

                return new ort.Tensor('float32', input, [1, channels, modelHeight, modelWidth]);
            }

            displayInferenceResults(results) {
                const resultsDiv = document.getElementById('results');
                const inferenceResults = document.getElementById('inferenceResults');

                resultsDiv.innerHTML = '';
                this.log('Displaying inference results');

                // This is a generic result display - adjust based on your model output
                for (const [key, tensor] of Object.entries(results)) {
                    const values = tensor.data;

                    // Example: display top 5 predictions for classification
                    const topResults = Array.from(values)
                        .map((val, idx) => ({ value: val, index: idx }))
                        .sort((a, b) => b.value - a.value)
                        .slice(0, 5);

                    topResults.forEach((result, i) => {
                        const resultItem = document.createElement('div');
                        resultItem.className = 'result-item';
                        resultItem.innerHTML = `
                            <span>Class ${result.index}</span>
                            <span class="confidence">${(result.value * 100).toFixed(2)}%</span>
                        `;
                        resultsDiv.appendChild(resultItem);
                    });
                }

                inferenceResults.style.display = 'block';
            }

            toggleLiveProcessing() {
                const button = document.getElementById('toggleProcessing');

                if (this.isProcessing) {
                    this.isProcessing = false;
                    if (this.animationId) {
                        cancelAnimationFrame(this.animationId);
                    }
                    button.textContent = 'Start Live Processing';
                    this.updateStatus('Live processing stopped');
                    this.log('Live processing stopped');
                } else {
                    this.isProcessing = true;
                    button.textContent = 'Stop Live Processing';
                    this.updateStatus('Live processing started', 'success');
                    this.log('Live processing started');
                    this.liveProcessing();
                }
            }

            liveProcessing() {
                if (!this.isProcessing) return;

                this.processFrame().then(() => {
                    this.animationId = requestAnimationFrame(() => this.liveProcessing());
                });
            }

            showLoading(show) {
                document.getElementById('loading').style.display = show ? 'block' : 'none';
            }
        }

        function onOpenCVReady() {
            console.log('OpenCV.js loaded');
            if (window.cameraApp) {
                window.cameraApp.isOpenCVReady = true;
                window.cameraApp.log('OpenCV is ready');
                window.cameraApp.updateStatus('‚úÖ OpenCV loaded successfully', 'success');
            }
        }

        function onOpenCVError() {
            console.error('Failed to load OpenCV.js');
            if (window.cameraApp) {
                window.cameraApp.log('ERROR: Failed to load OpenCV.js');
                window.cameraApp.updateStatus('‚ùå Failed to load OpenCV - check console', 'error');
                
                // Try loading again after delay
                setTimeout(() => {
                    window.cameraApp.log('Attempting to reload OpenCV...');
                    const script = document.createElement('script');
                    script.src = 'https://cdnjs.cloudflare.com/ajax/libs/opencv.js/4.8.0/opencv.js';
                    script.onload = onOpenCVReady;
                    script.onerror = onOpenCVError;
                    document.head.appendChild(script);
                }, 3000);
            }
        }

        // Fallback check in case onload doesn't fire
        function checkOpenCVLoaded() {
            if (typeof cv === 'undefined') {
                console.warn('OpenCV still not loaded after timeout');
                if (window.cameraApp) {
                    window.cameraApp.updateStatus('‚ö†Ô∏è OpenCV taking longer than expected to load', 'error');
                }
            }
        }
        setTimeout(checkOpenCVLoaded, 10000); // Check after 10 seconds

        // Initialize the app immediately
        function initializeApp() {
            console.log('Initializing app...');
            const app = new IntegratedCameraApp();
            window.cameraApp = app; // For debugging
            
            // Check if OpenCV is already loaded (might happen if script loads before this runs)
            if (typeof cv !== 'undefined' && cv.Mat) {
                app.isOpenCVReady = true;
                app.log('OpenCV already loaded');
            }
        }

        // Initialize the app when DOM is ready
        if (document.readyState === 'loading') {
            document.addEventListener('DOMContentLoaded', initializeApp);
        } else {
            initializeApp();
        }
    </script>

    <!-- OpenCV.js -->
    <!-- <script src="https://cdnjs.cloudflare.com/ajax/libs/opencv.js/4.8.0/opencv.js"  -->
    <script async src="../ext/opencv.js" onload="onOpenCVReady()" onerror="onOpenCVError()"></script>

</body>

</html>
