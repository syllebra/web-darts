<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <title>YOLOv8 Object Detection</title>
    <!-- <script src="https://cdn.jsdelivr.net/npm/eruda"></script> -->
    <script src="../ext/ort.min.js"></script>
    <style>
        canvas {
            display: block;
            border: 1px solid black;
            margin-top: 10px;
        }
    </style>
</head>

<body>
    <input id="uploadInput" type="file" />
    <div>
        <label><input type="radio" name="executionProvider" value="cpu"> CPU</label>
        <label><input type="radio" name="executionProvider" value="webgpu" checked> GPU</label>
        <button id="rerunButton">Re-run Inference</button>
    </div>
    <canvas></canvas>
    <script src="../utils/DebugConsole.js"></script>
    <script>
        // Default image URL to load on startup
        const DEFAULT_IMAGE_URL = '../dev/target_detector_test/03.jpg'; // Replace with your desired default image URL

        // Load default image on page load
        window.addEventListener('DOMContentLoaded', async () => {
            try {
                const response = await fetch(DEFAULT_IMAGE_URL);
                const blob = await response.blob();
                const [boxes, image] = await detect_objects_on_image(blob);
                draw_image_and_boxes(blob, boxes, image);
            } catch (error) {
                console.error('Error loading default image:', error);
            }
        });

        async function checkGPU() {
            if (!navigator.gpu) {
                throw Error("WebGPU not supported.");
            }

            const adapter = await navigator.gpu.requestAdapter();
            if (!adapter) {
                throw Error("Couldn't request WebGPU adapter.");
            }

            const device = await adapter.requestDevice();
        }
        checkGPU()
        /**
         * "Upload" button onClick handler: uploads selected image file
         * to backend, receives array of detected objects
         * and draws them on top of image
         */
        let model = null;
        let inputImage = null;
        let currentImage = null;
        const input = document.getElementById("uploadInput");
        const rerunButton = document.getElementById("rerunButton");

        rerunButton.addEventListener("click", async () => {
            if (currentImage) {
                model = null; // Force model reload with new provider
                const [boxes, image] = await detect_objects_on_image(currentImage);
                draw_image_and_boxes(currentImage, boxes, image);
            }
        });
        input.addEventListener("change", async (event) => {
            currentImage = event.target.files[0];
            const [boxes, image] = await detect_objects_on_image(currentImage);
            draw_image_and_boxes(currentImage, boxes, image);
        })

        /**
         * Function draws the image from provided file
         * and bounding boxes of detected objects on
         * top of the image
         * @param file Uploaded file object
         * @param boxes Array of bounding boxes in format [[x1,y1,x2,y2,object_type,probability],...]
         */
        function draw_image_and_boxes(file, boxes, image) {
            const img = new Image()
            img.src = URL.createObjectURL(file);
            img.onload = () => {
                const canvas = document.querySelector("canvas");
                canvas.width = img.width;
                canvas.height = img.height;
                const ctx = canvas.getContext("2d");
                ctx.drawImage(img, 0, 0);
                
                // Color mapping for each label
                const labelColors = {
                    "tip": "#FF0000",    // Red
                    "cal1": "#00FF00",    // Green
                    "cal2": "#0000FF",    // Blue
                    "cal3": "#FFFF00",    // Yellow
                    "cal4": "#FF00FF",    // Magenta
                    "dart": "#00FFFF",    // Cyan
                    "cross": "#FFA500",   // Orange
                    "D-Bull": "#800080",  // Purple
                    "Bull": "#008000"     // Dark Green
                };

                ctx.lineWidth = 3;
                ctx.font = "18px serif";
                boxes.forEach(([x1, y1, x2, y2, label]) => {
                    const labelName = yolo_classes[label];
                    const color = labelColors[labelName] || "#FFFFFF"; // Default to white if unknown
                    
                    ctx.strokeStyle = color;
                    ctx.fillStyle = color;
                    ctx.strokeRect(x1, y1, x2 - x1, y2 - y1);
                    
                    const width = ctx.measureText(labelName).width;
                    ctx.fillRect(x1, y1 - 18, width + 10, 20);
                    ctx.fillStyle = "#000000";
                    ctx.fillText(labelName, x1 + 5, y1 - 2);
                });
            }
        }

        /**
         * Function receives an image, passes it through YOLOv8 neural network
         * and returns an array of detected objects and their bounding boxes
         * @param buf Input image body
         * @returns Array of bounding boxes in format [[x1,y1,x2,y2,object_type,probability],..]
         */
        async function detect_objects_on_image(buf) {
            const [input, img_width, img_height, to_infer] = await prepare_input(buf);
            const outputs = await run_model(input);
            return process_output(outputs, img_width, img_height, to_infer);
        }

        /**
         * Function used to convert input image to tensor,
         * required as an input to YOLOv8 object detection
         * network.
         * @param buf Content of uploaded file
         * @returns Array of pixels
         */
        async function prepare_input(buf) {
            return new Promise(resolve => {
                const img = new Image();
                img.src = URL.createObjectURL(buf);
                img.onload = () => {
                    const [img_width, img_height] = [img.width, img.height]
                    const canvas = document.createElement("canvas");
                    canvas.width = 640;
                    canvas.height = 640;
                    const context = canvas.getContext("2d");
                    context.drawImage(img, 0, 0, 640, 640);
                    const imgData = context.getImageData(0, 0, 640, 640);
                    const pixels = imgData.data;

                    const red = [], green = [], blue = [];
                    for (let index = 0; index < pixels.length; index += 4) {
                        red.push(pixels[index] / 255.0);
                        green.push(pixels[index + 1] / 255.0);
                        blue.push(pixels[index + 2] / 255.0);
                    }
                    const input = [...red, ...green, ...blue];
                    resolve([input, img_width, img_height, imgData])
                }
            })
        }

        /**
         * Function used to pass provided input tensor to YOLOv8 neural network and return result
         * @param input Input pixels array
         * @returns Raw output of neural network as a flat array of numbers
         */
        async function run_model(input) {
            if(!model) {
                const provider = document.querySelector('input[name="executionProvider"]:checked').value;
                const options = provider === 'webgpu' ? { executionProviders: ['webgpu'] } : {};
                model = await ort.InferenceSession.create("../models/best_n_tip_boxes_cross_640_B.onnx", options);
                console.log(model)
            }
            inputImage = new ort.Tensor(Float32Array.from(input), [1, 3, 640, 640]);
            const outputs = await model.run({ images: inputImage });
            return outputs;
        }

        /**
         * Function used to convert RAW output from YOLOv8 to an array of detected objects.
         * Each object contain the bounding box of this object, the type of object and the probability
         * @param output Raw output of YOLOv8 network
         * @param img_width Width of original image
         * @param img_height Height of original image
         * @returns Array of detected objects in a format [[x1,y1,x2,y2,object_type,probability],..]
         */
        // function process_output(output, img_width, img_height, infered) {
        //     let boxes = [];
        //     for (let index = 0; index < 8400; index++) {
        //         const [class_id, prob] = [...Array(80).keys()]
        //             .map(col => [col, output[8400 * (col + 4) + index]])
        //             .reduce((accum, item) => item[1] > accum[1] ? item : accum, [0, 0]);
        //         if (prob < 0.5) {
        //             continue;
        //         }
        //         const label = yolo_classes[class_id];
        //         const xc = output[index];
        //         const yc = output[8400 + index];
        //         const w = output[2 * 8400 + index];
        //         const h = output[3 * 8400 + index];
        //         const x1 = (xc - w / 2);// / 640 * img_width;
        //         const y1 = (yc - h / 2);// / 640 * img_height;
        //         const x2 = (xc + w / 2);// / 640 * img_width;
        //         const y2 = (yc + h / 2);// / 640 * img_height;
        //         boxes.push([x1, y1, x2, y2, label, prob]);
        //     }

        //     boxes = boxes.sort((box1, box2) => box2[5] - box1[5])
        //     // const result = [];
        //     // while (boxes.length > 0) {
        //     //     result.push(boxes[0]);
        //     //     boxes = boxes.filter(box => iou(boxes[0], box) < 0.7);
        //     // }
        //     // return [result, infered];
        //     return [boxes, infered];
        // }

        /**
         * Function used to convert RAW output from YOLOv8 to an array of detected objects.
         * Each object contains the bounding box, class, and confidence score.
         * @param output Raw output of YOLOv8 network (Float32Array)
         * @param img_width Width of original image
         * @param img_height Height of original image
         * @returns Array of detected objects in format [[x1,y1,x2,y2,class_id,confidence], ...]
         */
        function process_output(outputs, img_width, img_height, inferred) {
            // YOLOv8 output format explanation:
            // - The output is a flat array of length 8400 * (num_classes + 4)
            // - For each of the 8400 anchor boxes, we have:
            //   - 4 box coordinates (xc, yc, w, h)
            //   - num_classes confidence scores
            // - In your case, num_classes is 9 (from your yolo_classes array)

            console.log(outputs)
            const output = outputs["output0"].data;
            const num_classes = outputs["output0"]["dims"][1]-4;//yolo_classes.length;
            let boxes = [];

            // Iterate through all 8400 anchor boxes
            for (let index = 0; index < 8400; index++) {
                // Get the class with highest confidence
                let max_class = 0;
                let max_confidence = 0;

                // Check class confidences (they start at offset 4*8400)
                for (let class_id = 0; class_id < num_classes; class_id++) {
                    const confidence = output[8400 * (4 + class_id) + index];
                    if (confidence > max_confidence) {
                        max_confidence = confidence;
                        max_class = class_id;
                    }
                }
                // Skip boxes with low confidence
                if (max_confidence < 0.5) {
                    continue;
                }

                const xc = output[index];          // x-center
                const yc = output[8400 + index];   // y-center
                const w = output[2 * 8400 + index];  // width
                const h = output[3 * 8400 + index];  // height

                // Convert from center+width to xyxy format
                const x1 = (xc - w / 2) * img_width / 640;
                const y1 = (yc - h / 2) * img_height / 640;
                const x2 = (xc + w / 2) * img_width / 640;
                const y2 = (yc + h / 2) * img_height / 640;
                const box = [x1, y1, x2, y2, max_class, max_confidence];
                boxes.push(box);
            }

            // Non-maximum suppression to remove overlapping boxes
            boxes.sort((a, b) => b[5] - a[5]); // Sort by confidence (descending)

            const final_boxes = [];
            while (boxes.length > 0) {
                final_boxes.push(boxes[0]);
                // Remove boxes that overlap too much with the current box
                boxes = boxes.filter(box => iou(boxes[0], box) < 0.85);
            }

            return [final_boxes, inferred];
            // return [boxes, inferred];
        }        

        /**
         * Function calculates "Intersection-over-union" coefficient for specified two boxes
         * https://pyimagesearch.com/2016/11/07/intersection-over-union-iou-for-object-detection/.
         * @param box1 First box in format: [x1,y1,x2,y2,object_class,probability]
         * @param box2 Second box in format: [x1,y1,x2,y2,object_class,probability]
         * @returns Intersection over union ratio as a float number
         */
        function iou(box1, box2) {
            return intersection(box1, box2) / union(box1, box2);
        }

        /**
         * Function calculates union area of two boxes.
         *     :param box1: First box in format [x1,y1,x2,y2,object_class,probability]
         *     :param box2: Second box in format [x1,y1,x2,y2,object_class,probability]
         *     :return: Area of the boxes union as a float number
         * @param box1 First box in format [x1,y1,x2,y2,object_class,probability]
         * @param box2 Second box in format [x1,y1,x2,y2,object_class,probability]
         * @returns Area of the boxes union as a float number
         */
        function union(box1, box2) {
            const [box1_x1, box1_y1, box1_x2, box1_y2] = box1;
            const [box2_x1, box2_y1, box2_x2, box2_y2] = box2;
            const box1_area = (box1_x2 - box1_x1) * (box1_y2 - box1_y1)
            const box2_area = (box2_x2 - box2_x1) * (box2_y2 - box2_y1)
            return box1_area + box2_area - intersection(box1, box2)
        }

        /**
         * Function calculates intersection area of two boxes
         * @param box1 First box in format [x1,y1,x2,y2,object_class,probability]
         * @param box2 Second box in format [x1,y1,x2,y2,object_class,probability]
         * @returns Area of intersection of the boxes as a float number
         */
        function intersection(box1, box2) {
            const [box1_x1, box1_y1, box1_x2, box1_y2] = box1;
            const [box2_x1, box2_y1, box2_x2, box2_y2] = box2;
            const x1 = Math.max(box1_x1, box2_x1);
            const y1 = Math.max(box1_y1, box2_y1);
            const x2 = Math.min(box1_x2, box2_x2);
            const y2 = Math.min(box1_y2, box2_y2);
            return (x2 - x1) * (y2 - y1)
        }

        /**
         * Array of YOLOv8 class labels
         */
        // const yolo_classes = [
        //     'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat',
        //     'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse',
        //     'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase',
        //     'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard',
        //     'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',
        //     'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', 'potted plant',
        //     'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven',
        //     'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush'
        // ];

        const yolo_classes = ["tip", "cal1", "cal2", "cal3", "cal4", "dart", "cross", "D-Bull", "Bull"];
    </script>
</body>

</html>
