<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <title>YOLOv8 Object Detection</title>
    <!-- <script src="https://cdn.jsdelivr.net/npm/eruda"></script> -->
    <script src="../ext/ort.min.js"></script>
    <style>
        canvas {
            display: block;
            border: 1px solid black;
            margin-top: 10px;
        }
    </style>
</head>

<body>
    <input id="uploadInput" type="file" />
    <div>
        <select id="modelSelect">
            <option value="">Loading models...</option>
        </select>
        <label><input type="radio" name="executionProvider" value="cpu"> CPU</label>
        <label><input type="radio" name="executionProvider" value="webgpu" checked> GPU</label>
        <button id="rerunButton">Re-run Inference</button>
        <button id="benchmarkButton">Run Benchmark</button>
        <div id="benchmarkResults"></div>
    </div>
    <canvas></canvas>
    <script src="../utils/DebugConsole.js"></script>
    
    <script>
        // Default image URL to load on startup
        const DEFAULT_IMAGE_URL = '../dev/target_detector_test/03.jpg'; // Replace with your desired default image URL

        // Load default image on page load
        window.addEventListener('DOMContentLoaded', async () => {
            //try {
                const response = await fetch(DEFAULT_IMAGE_URL);
                const blob = await response.blob();
                currentImage = blob;
                const [boxes, image] = await detect_objects_on_image(blob);
                draw_image_and_boxes(blob, boxes, image);
            // } catch (error) {
            //     console.error('Error loading default image:', error);
            // }
        });

        async function checkGPU() {
            if (!navigator.gpu) {
                throw Error("WebGPU not supported.");
            }

            const adapter = await navigator.gpu.requestAdapter();
            if (!adapter) {
                throw Error("Couldn't request WebGPU adapter.");
            }

            const device = await adapter.requestDevice();
        }
        checkGPU()
        /**
         * "Upload" button onClick handler: uploads selected image file
         * to backend, receives array of detected objects
         * and draws them on top of image
         */
        let model = null;
        let inputImage = null;
        let currentImage = null;
        let benchmarkResults = [];
        let modelsData = [];
        const benchmarkButton = document.getElementById("benchmarkButton");
        const benchmarkResultsDiv = document.getElementById("benchmarkResults");
        const modelSelect = document.getElementById("modelSelect");
        
        // Load models data
        fetch('../models/models.json')
            .then(response => response.json())
            .then(data => {
                modelsData = data;
                modelSelect.innerHTML = '';
                data.forEach((model, index) => {
                    const option = document.createElement('option');
                    option.value = index;
                    option.textContent = `${model.name} (${model.type} ${model.version}) - ${model.size}x${model.size}`;
                    modelSelect.appendChild(option);
                });
                modelSelect.value = 0;
            });

        benchmarkButton.addEventListener("click", async () => {
            if (modelsData.length === 0) {
                alert("Models data not loaded yet");
                return;
            }

            benchmarkResults = [];
            benchmarkResultsDiv.innerHTML = "Running benchmark...";
            
            // Run benchmarks for all models
            for (let i = 0; i < modelsData.length; i++) {
                modelSelect.value = i;
                benchmarkResultsDiv.innerHTML += `<h3>Testing ${modelsData[i].name} (${modelsData[i].type} ${modelsData[i].version})</h3>`;
                
                // Test GPU first
                document.querySelector('input[value="webgpu"]').checked = true;
                await runBenchmark("GPU");
                
                // Then test CPU
                document.querySelector('input[value="cpu"]').checked = true;
                await runBenchmark("CPU");
            }
            
            displayBenchmarkResults();
        });

        async function runBenchmark(providerName) {
            if (!currentImage) {
                alert("Please load an image first");
                return;
            }

            if (modelsData.length === 0) {
                alert("Models data not loaded yet");
                return;
            }

            // Get selected model
            const selectedModelIndex = modelSelect.value;
            const selectedModel = modelsData[selectedModelIndex];
            const modelFile = selectedModel.file;
            
            // Preload model once
            model = null;
            const provider = document.querySelector('input[name="executionProvider"]:checked').value;
            const options = provider === 'webgpu' ? { 
                executionProviders: ['webgpu'],
                graphOptimizationLevel: 'disabled'
            } : {
                executionProviders: ['wasm'],
                graphOptimizationLevel: 'disabled'
            };
            
            const model_path = `../models/${modelFile}`;
            try {
                model = await ort.InferenceSession.create(model_path, options);
                console.log(`${providerName} model loaded: ${modelFile}`);
            } catch (error) {
                console.error(`Error loading model ${modelFile}:`, error);
                benchmarkResultsDiv.innerHTML += `<p style="color:red">Failed to load model ${modelFile} for ${providerName}</p>`;
                return;
            }
            
            // Warmup
            await detect_objects_on_image(currentImage);
            
            // Run 5 inferences and measure time
            for (let i = 0; i < 5; i++) {
                const startTotal = performance.now();
                
                // Measure input preparation
                const startInput = performance.now();
                const [input] = await prepare_input(currentImage);
                const inputTime = performance.now() - startInput;
                
                // Measure model run
                const startModel = performance.now();
                await run_model(input);
                const modelTime = performance.now() - startModel;
                
                const totalTime = performance.now() - startTotal;
                
                benchmarkResults.push({
                    provider: providerName,
                    iteration: i+1,
                    inputTime: inputTime,
                    modelTime: modelTime,
                    totalTime: totalTime,
                    modelIndex: modelSelect.value
                });
                console.log(`${providerName} iteration ${i+1} - Input: ${inputTime.toFixed(2)}ms, Model: ${modelTime.toFixed(2)}ms, Total: ${totalTime.toFixed(2)}ms`);
            }
        }

        function displayBenchmarkResults() {
            // Group results by model and provider
            const resultsByModel = {};
            benchmarkResults.forEach(result => {
                if (!resultsByModel[result.modelIndex]) {
                    resultsByModel[result.modelIndex] = {
                        GPU: [],
                        CPU: []
                    };
                }
                resultsByModel[result.modelIndex][result.provider].push(result);
            });

            let html = `<h3>Benchmark Results</h3>`;
            
            // Generate results for each model
            Object.keys(resultsByModel).forEach(modelIndex => {
                const model = modelsData[modelIndex];
                const gpuResults = resultsByModel[modelIndex].GPU;
                const cpuResults = resultsByModel[modelIndex].CPU;
                
                if (gpuResults.length === 0 && cpuResults.length === 0) return;
                
                html += `<h4>${model.name} (${model.type} ${model.version}) - ${model.size}x${model.size}</h4>`;
                
                // Calculate averages
                const calculateAverages = (results) => {
                    if (results.length === 0) return null;
                    return {
                        input: results.reduce((sum, r) => sum + r.inputTime, 0) / results.length,
                        model: results.reduce((sum, r) => sum + r.modelTime, 0) / results.length,
                        total: results.reduce((sum, r) => sum + r.totalTime, 0) / results.length
                    };
                };
                
                const gpuAvg = calculateAverages(gpuResults);
                const cpuAvg = calculateAverages(cpuResults);
                
                if (gpuAvg) {
                    html += `<p>GPU Averages - Input: ${gpuAvg.input.toFixed(2)}ms, Model: ${gpuAvg.model.toFixed(2)}ms, Total: ${gpuAvg.total.toFixed(2)}ms</p>`;
                }
                if (cpuAvg) {
                    html += `<p>CPU Averages - Input: ${cpuAvg.input.toFixed(2)}ms, Model: ${cpuAvg.model.toFixed(2)}ms, Total: ${cpuAvg.total.toFixed(2)}ms</p>`;
                }
                if (gpuAvg && cpuAvg) {
                    html += `<p>Speed Ratio (Model Only): ${(cpuAvg.model/gpuAvg.model).toFixed(2)}x</p>`;
                }
                
                html += `<table border="1">
                    <tr><th>Provider</th><th>Iteration</th><th>Input (ms)</th><th>Model (ms)</th><th>Total (ms)</th></tr>`;
                
                // Add GPU results
                gpuResults.forEach(result => {
                    html += `<tr>
                        <td>${result.provider}</td>
                        <td>${result.iteration}</td>
                        <td>${result.inputTime.toFixed(2)}</td>
                        <td>${result.modelTime.toFixed(2)}</td>
                        <td>${result.totalTime.toFixed(2)}</td>
                    </tr>`;
                });
                
                // Add CPU results
                cpuResults.forEach(result => {
                    html += `<tr>
                        <td>${result.provider}</td>
                        <td>${result.iteration}</td>
                        <td>${result.inputTime.toFixed(2)}</td>
                        <td>${result.modelTime.toFixed(2)}</td>
                        <td>${result.totalTime.toFixed(2)}</td>
                    </tr>`;
                });
                
                html += `</table><br>`;
            });
            
            benchmarkResultsDiv.innerHTML = html;
        }
        const input = document.getElementById("uploadInput");
        const rerunButton = document.getElementById("rerunButton");

        rerunButton.addEventListener("click", async () => {
            console.log("Re-run button clicked, currentImage:", currentImage);
            if (currentImage) {
                console.log("Reloading model and running inference...");
                model = null; // Force model reload with new provider
                try {
                    const [boxes, image] = await detect_objects_on_image(currentImage);
                    console.log("Inference completed, drawing boxes...");
                    draw_image_and_boxes(currentImage, boxes, image);
                } catch (error) {
                    console.error("Error during re-run:", error);
                }
            } else {
                console.log("No currentImage available to process");
            }
        });
        input.addEventListener("change", async (event) => {
            currentImage = event.target.files[0];
            const [boxes, image] = await detect_objects_on_image(currentImage);
            draw_image_and_boxes(currentImage, boxes, image);
        })

        /**
         * Function draws the image from provided file
         * and bounding boxes of detected objects on
         * top of the image
         * @param file Uploaded file object
         * @param boxes Array of bounding boxes in format [[x1,y1,x2,y2,object_type,probability],...]
         */
        function draw_image_and_boxes(file, boxes, image) {
            const img = new Image()
            img.src = URL.createObjectURL(file);
            img.onload = () => {
                const canvas = document.querySelector("canvas");
                canvas.width = img.width;
                canvas.height = img.height;
                const ctx = canvas.getContext("2d");
                ctx.drawImage(img, 0, 0);
                
                // Color mapping for each label
                const labelColors = {
                    "tip": "#FF0000",    // Red
                    "cal1": "#00FF00",    // Green
                    "cal2": "#0000FF",    // Blue
                    "cal3": "#FFFF00",    // Yellow
                    "cal4": "#FF00FF",    // Magenta
                    "dart": "#00FFFF",    // Cyan
                    "cross": "#FFA500",   // Orange
                    "D-Bull": "#800080",  // Purple
                    "Bull": "#008000"     // Dark Green
                };

                ctx.lineWidth = 3;
                ctx.font = "18px serif";
                boxes.forEach(([x1, y1, x2, y2, label]) => {
                    const labelName = yolo_classes[label];
                    const color = labelColors[labelName] || "#FFFFFF"; // Default to white if unknown
                    
                    ctx.strokeStyle = color;
                    ctx.fillStyle = color;
                    ctx.strokeRect(x1, y1, x2 - x1, y2 - y1);
                    
                    const width = ctx.measureText(labelName).width;
                    ctx.fillRect(x1, y1 - 18, width + 10, 20);
                    ctx.fillStyle = "#000000";
                    ctx.fillText(labelName, x1 + 5, y1 - 2);
                });
            }
        }

        /**
         * Function receives an image, passes it through YOLOv8 neural network
         * and returns an array of detected objects and their bounding boxes
         * @param buf Input image body
         * @returns Array of bounding boxes in format [[x1,y1,x2,y2,object_type,probability],..]
         */
        async function detect_objects_on_image(buf) {
            const [input, img_width, img_height, to_infer] = await prepare_input(buf);
            const outputs = await run_model(input);
            return process_output(outputs, img_width, img_height, to_infer);
        }

        /**
         * Function used to convert input image to tensor,
         * required as an input to YOLOv8 object detection
         * network.
         * @param buf Content of uploaded file
         * @returns Array of pixels
         */
        async function prepare_input(buf) {
            return new Promise(resolve => {
                const img = new Image();
                img.src = URL.createObjectURL(buf);
                img.onload = () => {
                    const [img_width, img_height] = [img.width, img.height]
                    const selectedModelIndex = modelSelect.value;
                    const modelSize = modelsData[selectedModelIndex].size;
                    const canvas = document.createElement("canvas");
                    canvas.width = modelSize;
                    canvas.height = modelSize;
                    const context = canvas.getContext("2d");
                    context.drawImage(img, 0, 0, modelSize, modelSize);
                    const imgData = context.getImageData(0, 0, modelSize, modelSize);
                    const pixels = imgData.data;

                    const red = [], green = [], blue = [];
                    for (let index = 0; index < pixels.length; index += 4) {
                        red.push(pixels[index] / 255.0);
                        green.push(pixels[index + 1] / 255.0);
                        blue.push(pixels[index + 2] / 255.0);
                    }
                    const input = [...red, ...green, ...blue];
                    resolve([input, img_width, img_height, imgData])
                }
            })
        }

        /**
         * Function used to pass provided input tensor to YOLOv8 neural network and return result
         * @param input Input pixels array
         * @returns Raw output of neural network as a flat array of numbers
         */
        async function run_model(input) {
            if(!model) {
                const provider = document.querySelector('input[name="executionProvider"]:checked').value;
                const options = provider === 'webgpu' ? { executionProviders: ['webgpu'], graphOptimizationLevel: 'disabled' } : {};
                const model_path="../models/best_n_tip_boxes_cross_640_B_webgpu.onnx"
                model = await ort.InferenceSession.create(model_path, options);
                console.log(provider," => ONNX model loaded:", model)
            }
            inputImage = new ort.Tensor(Float32Array.from(input), [1, 3, 640, 640]);
            const outputs = await model.run({ images: inputImage });
            return outputs;
        }

        /**
         * Function used to convert RAW output from YOLOv8 to an array of detected objects.
         * Each object contain the bounding box of this object, the type of object and the probability
         * @param output Raw output of YOLOv8 network
         * @param img_width Width of original image
         * @param img_height Height of original image
         * @returns Array of detected objects in a format [[x1,y1,x2,y2,object_type,probability],..]
         */
        // function process_output(output, img_width, img_height, infered) {
        //     let boxes = [];
        //     for (let index = 0; index < 8400; index++) {
        //         const [class_id, prob] = [...Array(80).keys()]
        //             .map(col => [col, output[8400 * (col + 4) + index]])
        //             .reduce((accum, item) => item[1] > accum[1] ? item : accum, [0, 0]);
        //         if (prob < 0.5) {
        //             continue;
        //         }
        //         const label = yolo_classes[class_id];
        //         const xc = output[index];
        //         const yc = output[8400 + index];
        //         const w = output[2 * 8400 + index];
        //         const h = output[3 * 8400 + index];
        //         const x1 = (xc - w / 2);// / 640 * img_width;
        //         const y1 = (yc - h / 2);// / 640 * img_height;
        //         const x2 = (xc + w / 2);// / 640 * img_width;
        //         const y2 = (yc + h / 2);// / 640 * img_height;
        //         boxes.push([x1, y1, x2, y2, label, prob]);
        //     }

        //     boxes = boxes.sort((box1, box2) => box2[5] - box1[5])
        //     // const result = [];
        //     // while (boxes.length > 0) {
        //     //     result.push(boxes[0]);
        //     //     boxes = boxes.filter(box => iou(boxes[0], box) < 0.7);
        //     // }
        //     // return [result, infered];
        //     return [boxes, infered];
        // }

        /**
         * Function used to convert RAW output from YOLOv8 to an array of detected objects.
         * Each object contains the bounding box, class, and confidence score.
         * @param output Raw output of YOLOv8 network (Float32Array)
         * @param img_width Width of original image
         * @param img_height Height of original image
         * @returns Array of detected objects in format [[x1,y1,x2,y2,class_id,confidence], ...]
         */
        function process_output(outputs, img_width, img_height, inferred) {
            // YOLOv8 output format explanation:
            // - The output is a flat array of length 8400 * (num_classes + 4)
            // - For each of the 8400 anchor boxes, we have:
            //   - 4 box coordinates (xc, yc, w, h)
            //   - num_classes confidence scores
            // - In your case, num_classes is 9 (from your yolo_classes array)

            console.log(outputs)
            const output = outputs["output0"].data;
            const num_classes = outputs["output0"]["dims"][1]-4;//yolo_classes.length;
            let boxes = [];

            const selectedModelIndex = modelSelect.value;
            const modelSize = modelsData[selectedModelIndex].size;

            // Iterate through all 8400 anchor boxes
            for (let index = 0; index < 8400; index++) {
                // Get the class with highest confidence
                let max_class = 0;
                let max_confidence = 0;

                // Check class confidences (they start at offset 4*8400)
                for (let class_id = 0; class_id < num_classes; class_id++) {
                    const confidence = output[8400 * (4 + class_id) + index];
                    if (confidence > max_confidence) {
                        max_confidence = confidence;
                        max_class = class_id;
                    }
                }
                // Skip boxes with low confidence
                if (max_confidence < 0.5) {
                    continue;
                }

                const xc = output[index];          // x-center
                const yc = output[8400 + index];   // y-center
                const w = output[2 * 8400 + index];  // width
                const h = output[3 * 8400 + index];  // height

                // Convert from center+width to xyxy format
                const x1 = (xc - w / 2) * img_width / modelSize;
                const y1 = (yc - h / 2) * img_height / modelSize;
                const x2 = (xc + w / 2) * img_width / modelSize;
                const y2 = (yc + h / 2) * img_height / modelSize;
                const box = [x1, y1, x2, y2, max_class, max_confidence];
                boxes.push(box);
            }

            // Non-maximum suppression to remove overlapping boxes
            boxes.sort((a, b) => b[5] - a[5]); // Sort by confidence (descending)

            const final_boxes = [];
            while (boxes.length > 0) {
                final_boxes.push(boxes[0]);
                // Remove boxes that overlap too much with the current box
                boxes = boxes.filter(box => iou(boxes[0], box) < 0.85);
            }

            return [final_boxes, inferred];
            // return [boxes, inferred];
        }        

        /**
         * Function calculates "Intersection-over-union" coefficient for specified two boxes
         * https://pyimagesearch.com/2016/11/07/intersection-over-union-iou-for-object-detection/.
         * @param box1 First box in format: [x1,y1,x2,y2,object_class,probability]
         * @param box2 Second box in format: [x1,y1,x2,y2,object_class,probability]
         * @returns Intersection over union ratio as a float number
         */
        function iou(box1, box2) {
            return intersection(box1, box2) / union(box1, box2);
        }

        /**
         * Function calculates union area of two boxes.
         *     :param box1: First box in format [x1,y1,x2,y2,object_class,probability]
         *     :param box2: Second box in format [x1,y1,x2,y2,object_class,probability]
         *     :return: Area of the boxes union as a float number
         * @param box1 First box in format [x1,y1,x2,y2,object_class,probability]
         * @param box2 Second box in format [x1,y1,x2,y2,object_class,probability]
         * @returns Area of the boxes union as a float number
         */
        function union(box1, box2) {
            const [box1_x1, box1_y1, box1_x2, box1_y2] = box1;
            const [box2_x1, box2_y1, box2_x2, box2_y2] = box2;
            const box1_area = (box1_x2 - box1_x1) * (box1_y2 - box1_y1)
            const box2_area = (box2_x2 - box2_x1) * (box2_y2 - box2_y1)
            return box1_area + box2_area - intersection(box1, box2)
        }

        /**
         * Function calculates intersection area of two boxes
         * @param box1 First box in format [x1,y1,x2,y2,object_class,probability]
         * @param box2 Second box in format [x1,y1,x2,y2,object_class,probability]
         * @returns Area of intersection of the boxes as a float number
         */
        function intersection(box1, box2) {
            const [box1_x1, box1_y1, box1_x2, box1_y2] = box1;
            const [box2_x1, box2_y1, box2_x2, box2_y2] = box2;
            const x1 = Math.max(box1_x1, box2_x1);
            const y1 = Math.max(box1_y1, box2_y1);
            const x2 = Math.min(box1_x2, box2_x2);
            const y2 = Math.min(box1_y2, box2_y2);
            return (x2 - x1) * (y2 - y1)
        }

        /**
         * Array of YOLOv8 class labels
         */
        // const yolo_classes = [
        //     'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat',
        //     'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse',
        //     'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase',
        //     'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard',
        //     'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',
        //     'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', 'potted plant',
        //     'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven',
        //     'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush'
        // ];

        const yolo_classes = ["tip", "cal1", "cal2", "cal3", "cal4", "dart", "cross", "D-Bull", "Bull"];
    </script>
</body>

</html>
